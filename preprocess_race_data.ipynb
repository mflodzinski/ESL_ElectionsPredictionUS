{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_percentages_with_suffix(row, suffix):\n",
    "    \"\"\"\n",
    "    Calculate percentage values for demographic groups dynamically based on a suffix.\n",
    "    Returns:\n",
    "        pandas.Series - The row with updated percentage values.\n",
    "    \"\"\"\n",
    "    columns = [f\"hispanic_{suffix}\", f\"white_{suffix}\", f\"black_{suffix}\", f\"asian_{suffix}\"]\n",
    "    total = sum(row[col] for col in columns if col in row)\n",
    "    \n",
    "    if total > 0:\n",
    "        for col in columns:\n",
    "            if col in row:\n",
    "                row[col] = (row[col] / total)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess 2000 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'data/race_2000.csv'\n",
    "df_race_2000 = pd.read_csv(csv_file_path)[['Geography', 'Population Groups', 'Number!!Total population']]\n",
    "\n",
    "def process_group(fips, group):\n",
    "    row = {\"fips\": fips}\n",
    "    population_groups = group.set_index('Population Groups')['Number!!Total population']\n",
    "    \n",
    "    # Hispanic population logic\n",
    "    if 'Hispanic or Latino (of any race) (200-299)' in population_groups:\n",
    "        row[\"hispanic_2000\"] = population_groups['Hispanic or Latino (of any race) (200-299)']\n",
    "    else:\n",
    "        row[\"hispanic_2000\"] = (\n",
    "            population_groups.get('White alone', 0) - population_groups.get('White alone, not Hispanic or Latino', 0)\n",
    "            if 'White alone' in population_groups and 'White alone, not Hispanic or Latino' in population_groups\n",
    "            else 0\n",
    "        )\n",
    "    \n",
    "    # Assign other population groups\n",
    "    row[\"white_2000\"] = population_groups.get('White alone, not Hispanic or Latino', \n",
    "                     population_groups.get('White alone', 0))\n",
    "    row[\"black_2000\"] = population_groups.get('Black or African American alone', 0)\n",
    "    row[\"asian_2000\"] = population_groups.get('Asian alone (400-499)', 0)\n",
    "    row[\"total_2000\"] = population_groups.get('Total population', 0)\n",
    "    return row\n",
    "\n",
    "df_race_2000 = pd.DataFrame(\n",
    "    process_group(fips, group)\n",
    "    for fips, group in df_race_2000.groupby('Geography')\n",
    ")\n",
    "\n",
    "df_race_2000['fips'] = df_race_2000['fips'].str.replace('1600000US', '')\n",
    "df_race_2000.rename(columns={'Geography': 'fips'}, inplace=True)\n",
    "df_race_2000 = df_race_2000.apply(calculate_percentages_with_suffix, axis=1, suffix=\"2000\")\n",
    "\n",
    "# Change wrong values\n",
    "df_race_2000.loc[df_race_2000['fips'] == \"1319007\", 'fips'] = \"1319000\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess 2010 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'data/race_2010.csv'\n",
    "df_2010 = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Remove unwanted artefacts\n",
    "df_2010['Total'] = df_2010['Total'].str.replace(r'\\(.*?\\)', '', regex=True)\n",
    "\n",
    "columns_to_extract = {\n",
    "    \"Geography\": \"fips\",\n",
    "    \"Total\": \"total_2010\",\n",
    "    \"Total!!Hispanic or Latino\": \"hispanic_2010\",\n",
    "    \"Total!!Not Hispanic or Latino!!Population of one race!!White alone\": \"white_2010\",\n",
    "    \"Total!!Not Hispanic or Latino!!Population of one race!!Black or African American alone\": \"black_2010\",\n",
    "    \"Total!!Not Hispanic or Latino!!Population of one race!!Asian alone\": \"asian_2010\",\n",
    "}\n",
    "\n",
    "df_race_2010 = df_2010[list(columns_to_extract.keys())].rename(columns=columns_to_extract)\n",
    "df_race_2010['fips'] = df_race_2010['fips'].str.replace('1600000US', '')\n",
    "df_race_2010 = df_race_2010.apply(calculate_percentages_with_suffix, axis=1, suffix=\"2010\")\n",
    "\n",
    "# Change wrong values\n",
    "df_race_2010.loc[df_race_2010['fips'] == \"2127982\", 'fips'] = \"2148000\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess 2020 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'data/race_2020.csv'\n",
    "df_2020 = pd.read_csv(csv_file_path)\n",
    "\n",
    "columns_to_extract = {\n",
    "    \"Geography\": \"fips\",\n",
    "    \" !!Total:\": \"total_2020\",\n",
    "    \" !!Total:!!Hispanic or Latino\": \"hispanic_2020\",\n",
    "    \" !!Total:!!Not Hispanic or Latino:!!Population of one race:!!White alone\": \"white_2020\",\n",
    "    \" !!Total:!!Not Hispanic or Latino:!!Population of one race:!!Black or African American alone\": \"black_2020\",\n",
    "    \" !!Total:!!Not Hispanic or Latino:!!Population of one race:!!Asian alone\": \"asian_2020\",\n",
    "}\n",
    "\n",
    "df_race_2020 = df_2020[list(columns_to_extract.keys())].rename(columns=columns_to_extract)\n",
    "df_race_2020['fips'] = df_race_2020['fips'].str.replace('1600000US', '')\n",
    "df_race_2020 = df_race_2020.apply(calculate_percentages_with_suffix, axis=1, suffix=\"2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>total_2020</th>\n",
       "      <th>hispanic_2020</th>\n",
       "      <th>white_2020</th>\n",
       "      <th>black_2020</th>\n",
       "      <th>asian_2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0100100</td>\n",
       "      <td>133</td>\n",
       "      <td>0.030075</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.255639</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0100124</td>\n",
       "      <td>2358</td>\n",
       "      <td>0.029476</td>\n",
       "      <td>0.509019</td>\n",
       "      <td>0.454905</td>\n",
       "      <td>0.006599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0100460</td>\n",
       "      <td>4366</td>\n",
       "      <td>0.043169</td>\n",
       "      <td>0.408918</td>\n",
       "      <td>0.545541</td>\n",
       "      <td>0.002372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0100484</td>\n",
       "      <td>659</td>\n",
       "      <td>0.012638</td>\n",
       "      <td>0.984202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0100676</td>\n",
       "      <td>225</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.085973</td>\n",
       "      <td>0.900452</td>\n",
       "      <td>0.009050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31904</th>\n",
       "      <td>7287638</td>\n",
       "      <td>670</td>\n",
       "      <td>0.997010</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31905</th>\n",
       "      <td>7287863</td>\n",
       "      <td>5196</td>\n",
       "      <td>0.993638</td>\n",
       "      <td>0.005398</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.000193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31906</th>\n",
       "      <td>7288035</td>\n",
       "      <td>13569</td>\n",
       "      <td>0.995278</td>\n",
       "      <td>0.003837</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31907</th>\n",
       "      <td>7288121</td>\n",
       "      <td>769</td>\n",
       "      <td>0.994792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.001302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31908</th>\n",
       "      <td>7288293</td>\n",
       "      <td>1418</td>\n",
       "      <td>0.995063</td>\n",
       "      <td>0.004937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31909 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          fips  total_2020  hispanic_2020  white_2020  black_2020  asian_2020\n",
       "0      0100100         133       0.030075    0.714286    0.255639    0.000000\n",
       "1      0100124        2358       0.029476    0.509019    0.454905    0.006599\n",
       "2      0100460        4366       0.043169    0.408918    0.545541    0.002372\n",
       "3      0100484         659       0.012638    0.984202    0.000000    0.003160\n",
       "4      0100676         225       0.004525    0.085973    0.900452    0.009050\n",
       "...        ...         ...            ...         ...         ...         ...\n",
       "31904  7287638         670       0.997010    0.001495    0.000000    0.001495\n",
       "31905  7287863        5196       0.993638    0.005398    0.000771    0.000193\n",
       "31906  7288035       13569       0.995278    0.003837    0.000369    0.000516\n",
       "31907  7288121         769       0.994792    0.000000    0.003906    0.001302\n",
       "31908  7288293        1418       0.995063    0.004937    0.000000    0.000000\n",
       "\n",
       "[31909 rows x 6 columns]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_race_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_and_normalize_columns(df, columns, threshold=0.00001):\n",
    "    \"\"\"\n",
    "    Combines setting small values to zero and ensuring the specified columns sum to 1.\n",
    "    Returns:\n",
    "        pd.DataFrame: The modified DataFrame with adjusted and normalized columns.\n",
    "    \"\"\"\n",
    "    if not all(column in df.columns for column in columns):\n",
    "        raise ValueError(\"Some specified columns are not present in the DataFrame.\")\n",
    "\n",
    "    for column in columns:\n",
    "        df[column] = df[column].apply(lambda x: 0 if x < threshold else x)\n",
    "\n",
    "    column_sums = df[columns].sum(axis=1)\n",
    "    df[columns] = df[columns].div(column_sums, axis=0)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_patterns = {\n",
    "    'df_race_2000': ['hispanic_2000', 'white_2000', 'black_2000', 'asian_2000'],\n",
    "    'df_race_2010': ['hispanic_2010', 'white_2010', 'black_2010', 'asian_2010'],\n",
    "    'df_race_2020': ['hispanic_2020', 'white_2020', 'black_2020', 'asian_2020']\n",
    "}\n",
    "\n",
    "# df_race_2000, df_race_2010, df_race_2020 should be defined\n",
    "for df_name, columns in column_patterns.items():\n",
    "    df = globals()[df_name]\n",
    "    globals()[df_name] = adjust_and_normalize_columns(df, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge race datasets for easy lookup\n",
    "columns_to_estimate = ['hispanic', 'white', 'black', 'asian']\n",
    "\n",
    "race_data = df_race_2000[['fips', 'total_2000'] + [f'{col}_2000' for col in columns_to_estimate]].merge(\n",
    "    df_race_2010[['fips', 'total_2010'] + [f'{col}_2010' for col in columns_to_estimate]], on='fips'\n",
    ").merge(\n",
    "    df_race_2020[['fips', 'total_2020'] + [f'{col}_2020' for col in columns_to_estimate]], on='fips'\n",
    ")\n",
    "\n",
    "# Convert the 'fips' column to integers\n",
    "race_data['fips'] = race_data['fips'].astype(int)\n",
    "race_data = race_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_values_for_dataframe(df, race_data, columns):\n",
    "    \"\"\"\n",
    "    Estimate values for each row in a DataFrame based on given year and fips.\n",
    "    Returns:\n",
    "        pd.DataFrame: Original DataFrame with estimated values merged.\n",
    "    \"\"\"\n",
    "\n",
    "    def predict_linear_for_year(y_observed, x_observed, target_year):\n",
    "        \"\"\"\n",
    "        Predict the value for a given year using linear fitting.\n",
    "        \"\"\"\n",
    "        def linear_model(x, a, b):\n",
    "            return a * x + b\n",
    "\n",
    "        params, _ = curve_fit(linear_model, x_observed, y_observed)\n",
    "        predicted_value = linear_model(target_year, *params)\n",
    "        return predicted_value\n",
    "\n",
    "    observed_years = np.array([2000, 2010, 2020])\n",
    "    estimated_values = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        year = row['year']\n",
    "        fips = row['fips']\n",
    "        race_row = race_data[race_data['fips'] == fips]\n",
    "\n",
    "        if race_row.empty:\n",
    "            estimated_values.append({col: np.nan for col in columns})\n",
    "            continue\n",
    "\n",
    "        race_row = race_row.iloc[0]\n",
    "\n",
    "        estimates = {}\n",
    "        for col in columns:\n",
    "            y_observed = np.array([\n",
    "                race_row[f'{col}_2000'],\n",
    "                race_row[f'{col}_2010'],\n",
    "                race_row[f'{col}_2020']\n",
    "            ])\n",
    "            estimates[col] = predict_linear_for_year(y_observed, observed_years, year)\n",
    "\n",
    "        estimated_values.append(estimates)\n",
    "\n",
    "    estimated_df = pd.DataFrame(estimated_values)\n",
    "    result_df = pd.concat([df.reset_index(drop=True), estimated_df], axis=1)\n",
    "\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_estimate = ['total', 'hispanic', 'white', 'black', 'asian']\n",
    "\n",
    "df_mayor = pd.read_csv('data/data_mayoral.csv')\n",
    "df_mayor = estimate_values_for_dataframe(df_mayor, race_data, columns_to_estimate)\n",
    "df_mayor['total'] = df_mayor['total'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_abb</th>\n",
       "      <th>geo_name</th>\n",
       "      <th>year</th>\n",
       "      <th>contest</th>\n",
       "      <th>fips</th>\n",
       "      <th>full_name_rep</th>\n",
       "      <th>vote_share_rep</th>\n",
       "      <th>incumbent_rep</th>\n",
       "      <th>contributor.cfscore_rep</th>\n",
       "      <th>prob_democrat_rep</th>\n",
       "      <th>...</th>\n",
       "      <th>percent_white</th>\n",
       "      <th>percent_black</th>\n",
       "      <th>percent_hispanic</th>\n",
       "      <th>percent_asian_american</th>\n",
       "      <th>pres_pctD</th>\n",
       "      <th>total</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>white</th>\n",
       "      <th>black</th>\n",
       "      <th>asian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DE</td>\n",
       "      <td>wilmington</td>\n",
       "      <td>1992</td>\n",
       "      <td>151000_2019_10_montgomery_AL_Mayor_mayor_1</td>\n",
       "      <td>1077580</td>\n",
       "      <td>beatrice patton carroll</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.011667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291716</td>\n",
       "      <td>0.582597</td>\n",
       "      <td>0.101948</td>\n",
       "      <td>0.013929</td>\n",
       "      <td>0.891903</td>\n",
       "      <td>73060</td>\n",
       "      <td>0.086214</td>\n",
       "      <td>0.337033</td>\n",
       "      <td>0.570731</td>\n",
       "      <td>0.006021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DE</td>\n",
       "      <td>wilmington</td>\n",
       "      <td>1996</td>\n",
       "      <td>2148000_1998_11_louisville_KY_Mayor_mayor_1</td>\n",
       "      <td>1077580</td>\n",
       "      <td>bradley zuber</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.927143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291716</td>\n",
       "      <td>0.582597</td>\n",
       "      <td>0.101948</td>\n",
       "      <td>0.013929</td>\n",
       "      <td>0.890173</td>\n",
       "      <td>72707</td>\n",
       "      <td>0.094095</td>\n",
       "      <td>0.327885</td>\n",
       "      <td>0.571025</td>\n",
       "      <td>0.006995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DE</td>\n",
       "      <td>wilmington</td>\n",
       "      <td>2004</td>\n",
       "      <td>2205000_2016_12_baton rouge_LA_Mayor_mayor_1</td>\n",
       "      <td>1077580</td>\n",
       "      <td>robert bovell</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.776190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291716</td>\n",
       "      <td>0.582597</td>\n",
       "      <td>0.101948</td>\n",
       "      <td>0.013929</td>\n",
       "      <td>0.886721</td>\n",
       "      <td>72000</td>\n",
       "      <td>0.109856</td>\n",
       "      <td>0.309588</td>\n",
       "      <td>0.571614</td>\n",
       "      <td>0.008942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DE</td>\n",
       "      <td>wilmington</td>\n",
       "      <td>2016</td>\n",
       "      <td>1263000_2021_11_st. petersburg_FL_Mayor_mayor_1</td>\n",
       "      <td>1077580</td>\n",
       "      <td>robert martin</td>\n",
       "      <td>0.118280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291716</td>\n",
       "      <td>0.582597</td>\n",
       "      <td>0.101948</td>\n",
       "      <td>0.013929</td>\n",
       "      <td>0.878289</td>\n",
       "      <td>70941</td>\n",
       "      <td>0.133499</td>\n",
       "      <td>0.282142</td>\n",
       "      <td>0.572496</td>\n",
       "      <td>0.011863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DC</td>\n",
       "      <td>washington</td>\n",
       "      <td>1990</td>\n",
       "      <td>2404000_2020_11_baltimore_MD_Mayor_mayor_1</td>\n",
       "      <td>1150000</td>\n",
       "      <td>maurice turner</td>\n",
       "      <td>0.113402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.843333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.365785</td>\n",
       "      <td>0.463143</td>\n",
       "      <td>0.109994</td>\n",
       "      <td>0.048946</td>\n",
       "      <td>0.914489</td>\n",
       "      <td>503623</td>\n",
       "      <td>0.058937</td>\n",
       "      <td>0.229147</td>\n",
       "      <td>0.698828</td>\n",
       "      <td>0.013088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_abb    geo_name  year  \\\n",
       "0        DE  wilmington  1992   \n",
       "1        DE  wilmington  1996   \n",
       "2        DE  wilmington  2004   \n",
       "3        DE  wilmington  2016   \n",
       "4        DC  washington  1990   \n",
       "\n",
       "                                           contest     fips  \\\n",
       "0       151000_2019_10_montgomery_AL_Mayor_mayor_1  1077580   \n",
       "1      2148000_1998_11_louisville_KY_Mayor_mayor_1  1077580   \n",
       "2     2205000_2016_12_baton rouge_LA_Mayor_mayor_1  1077580   \n",
       "3  1263000_2021_11_st. petersburg_FL_Mayor_mayor_1  1077580   \n",
       "4       2404000_2020_11_baltimore_MD_Mayor_mayor_1  1150000   \n",
       "\n",
       "             full_name_rep  vote_share_rep  incumbent_rep  \\\n",
       "0  beatrice patton carroll        0.090000            0.0   \n",
       "1            bradley zuber        0.390000            0.0   \n",
       "2            robert bovell        0.270000            0.0   \n",
       "3            robert martin        0.118280            0.0   \n",
       "4           maurice turner        0.113402            0.0   \n",
       "\n",
       "   contributor.cfscore_rep  prob_democrat_rep  ... percent_white  \\\n",
       "0                 1.011667                0.0  ...      0.291716   \n",
       "1                 0.927143                0.0  ...      0.291716   \n",
       "2                 0.776190                0.0  ...      0.291716   \n",
       "3                 1.010000                0.0  ...      0.291716   \n",
       "4                 0.843333                0.0  ...      0.365785   \n",
       "\n",
       "  percent_black percent_hispanic percent_asian_american  pres_pctD   total  \\\n",
       "0      0.582597         0.101948               0.013929   0.891903   73060   \n",
       "1      0.582597         0.101948               0.013929   0.890173   72707   \n",
       "2      0.582597         0.101948               0.013929   0.886721   72000   \n",
       "3      0.582597         0.101948               0.013929   0.878289   70941   \n",
       "4      0.463143         0.109994               0.048946   0.914489  503623   \n",
       "\n",
       "   hispanic     white     black     asian  \n",
       "0  0.086214  0.337033  0.570731  0.006021  \n",
       "1  0.094095  0.327885  0.571025  0.006995  \n",
       "2  0.109856  0.309588  0.571614  0.008942  \n",
       "3  0.133499  0.282142  0.572496  0.011863  \n",
       "4  0.058937  0.229147  0.698828  0.013088  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mayor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mayor.to_csv('data/data_mayoral.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
